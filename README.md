# Rock-Paper-ScissorS

This project integrates computer vision, robotics, and machine learning to create a humanoid robotic arm capable of playing the classic game Rock-Paper-Scissors (RPS) in real time. The system detects human gestures using a YOLO-based model, determines the optimal robot response, and performs corresponding gestures using an Arduino-controlled robotic arm.
